# Application de datawarehouse Pix

## Enjeux et contraintes
Ce projet a pour but de mettre √† disposition des ressources facilement exploitables et r√©glementaires aupr√®s :
- d'utilisateurs internes (d√©veloppeurs, PO, support, m√©tiers, ...)
- d'utilisateurs externes (partenaires, membres d'une organisation dans PixOrga, ...)

Les contraintes majeures sont :
- disposer des donn√©es les plus r√©centes
- ne pas impacter la performance de la BDD
- ne donner acc√®s qu'aux utilisateurs autoris√©s.

## Approche
Pour respecter nos enjeux, nous avons dessin√© l'approche suivante :
- importer chaque nuit _l'int√©gralit√©_ des donn√©es de production dans une BDD dite "interne"
- importer chaque nuit _une partie_ des donn√©es de production dans une BDD dite "externe"
- dans Metabase, les utilisateurs externes sont r√©glementairement restraints √† l'utilisation de la BDD "externe"
- suite √† l'import, cr√©er des objets suppl√©mentaires pour assurer un temps d'ex√©cution des rapports acceptables (index, vues mat√©rialis√©es,...)

## Produit
Les possibilit√©s suivantes sont disponibles :
- ex√©cuter des rapports dans Metabase
- ex√©cuter des requ√™tes SQL

## Pr√©-requis
Ce projet est pr√©vu pour √™tre d√©ploy√© sur une application Scalingo associ√©e √† une base de donn√©e PostgreSQL.

Des variables d'environnement sont mises en place afin de garder un seul repository partag√© par les applications.

## Utilisation sur Scalingo

### Installation
Alimenter les variables d'environnement document√©es dans le fichier [sample.env](sample.env)

Pour satisfaire les contraintes de d√©ploiement Scalingo, le [Procfile](Procfile) d√©clare un conteneur de type `web` qui d√©marre un serveur Web "vide".

Une fois l'application cr√©√©e et d√©ploy√©e une premi√®re fois, il faut :
- mettre √† 0 le nombre de conteneurs de type `web`
- mettre √† 1 le nombre de conteneurs de type `background`.
 
### R√©solution de probl√®mes

#### Analyse de la cause

Connectez-vous √† `bull`
```shell
scalingo --region osc-secnum-fr1 --app pix-datawarehouse-production run bull-repl
connect "Replication queue"
#connect "Incremental replication queue"
#connect "Learning Content replication queue"
failed
stats
```

Alternativement, se connecter √† `redis`
```shell
scalingo --region osc-secnum-fr1 --app pix-datawarehouse-production redis-console
KEYS *
GET <KEY>
```

#### Relance
Une fois que la cause du probl√®me a √©t√© corrig√©e:
- s'il est important que les donn√©es soient disponibles le jour m√™me, il est possible de lancer le traitement manuellement;
- sinon ne rien faire, le traitement sera ex√©cut√© la nuit prochaine.

üß® Le traitement peut avoir des impacts sur les temps de r√©ponses des applications, car il utilise les ressources BDD.
Monitorez le % CPU BDD et le temps de r√©ponse des requ√™tes HTTP pour arr√™ter le traitement si besoin. Pour cela, stopper le conteneur `background`.

##### Sur la BDD destin√©e aux internes

Deux traitements (dump et incr√©mentale) sont ex√©cut√©s chaque nuit
* si l'un d'eux √©choue, le relancer
* si les deux √©chouent, les relancer parall√®lement 

Lancer la r√©plication par dump
``` bash
scalingo run --region osc-secnum-fr1 -a pix-datawarehouse-production npm run restart:full-replication
```

Lancer la r√©plication incr√©mentale
``` bash
scalingo run --region osc-secnum-fr1 -a pix-datawarehouse-production npm run restart:incremental-replication
```

##### Sur la BDD destin√©e aux externes
Lancer la r√©plication par dump
``` bash
scalingo run --region osc-secnum-fr1 -a pix-datawarehouse-ex-production npm run restart:full-replication
```

##### Ex√©cution partielle
Dans certains cas, le besoin est de relancer uniquement les op√©rations de fin de r√©plication

###### Importer le r√©f√©rentiel p√©dagogique
``` bash
scalingo run --region osc-secnum-fr1 -a pix-datawarehouse-production npm run restart:learning-content-replication
```

###### Relancer les notifications de fin
``` bash
scalingo run --region osc-secnum-fr1 -a pix-datawarehouse-production npm run restart:notification
```

###### Enrichissement
Cr√©ation index, vues..
``` bash
node -e "steps=require('./src/steps'); steps.addEnrichment(require ('./src/config/extract-configuration-from-environment')())"
```

## D√©veloppement et ex√©cution en local

### Installation
Installez le d√©p√¥t
``` bash
git clone git@github.com:1024pix/pix-db-replication.git && cd pix-db-replication
nvm use
npm run preinstall
```

D√©marrer le serveur de BDD
````shell
docker-compose up --detach
````

Cr√©er et charger les BDD
````shell
npm run local:setup-databases
````

V√©rifiez que la source et la cible sont accessibles et qu'elles contiennent des donn√©es
````shell
psql postgres://source_user@localhost/source_database
psql postgres://target_user@localhost/target_database
````

Installez le CLI Bull
`npm install bull-repl -g`


### Param√©trage
Cr√©er un fichier `.env` √† partir du fichier [sample.env](sample.env)

### Ex√©cution

#### R√©plication compl√®te

Modifier le .env
``` bash
DATABASE_URL=postgresql://target_user@localhost/target_database
BACKUP_MODE= {}
RESTORE_FK_CONSTRAINTS=true
```

Lancer la r√©plication
``` bash
node -e "steps=require('./src/steps'); steps.fullReplicationAndEnrichment(require ('./src/config/extract-configuration-from-environment')())"
```

Au bout de 5 minutes, vous devez obtenir le message
``` bash
"msg":"enrichment.add - Ended","time":"2021-01-08T08:26:13.000Z","v":0}
"msg":"Import and enrichment done","time":"2021-01-08T08:26:13.000Z","v":0}
```

Pensez √† recr√©er le backup sur le filesystem local, supprim√© par la restauration
``` bash
git checkout data/source.pgsql
```

#### R√©plication incr√©mentale

##### Initialiser l'environnement

Supprimer les FK sortantes des tables √† copier
``` bash
psql postgresql://target_user@localhost/target_database
```

```sql
ALTER TABLE answers DROP CONSTRAINT "answers_assessmentid_foreign";
ALTER TABLE "knowledge-elements" DROP CONSTRAINT "knowledge_elements_answerid_foreign";
ALTER TABLE "knowledge-elements" DROP CONSTRAINT "knowledge_elements_assessmentid_foreign";
ALTER TABLE "knowledge-elements" DROP CONSTRAINT "knowledge_elements_userid_foreign";
```

##### Param√©trer
Modifier le .env
``` bash
SOURCE_DATABASE_URL=postgresql://source_user@localhost/source_database
TARGET_DATABASE_URL=postgresql://target_user@localhost/target_database
BACKUP_MODE='{"knowledge-elements":"incremental", "knowledge-element-snapshots":"incremental","answers":"incremental"}'
RESTORE_FK_CONSTRAINTS=false
```

##### Ex√©cuter
Ex√©cuter
``` bash
node ./src/run-replicate-incrementally.js
```

#### Ex√©cution partielle
Dans certains cas, le besoin est de relancer uniquement les op√©rations de fin de r√©plication

##### Importer le r√©f√©rentiel p√©dagogique
``` bash
npm run local:learning-content
```

##### Enrichissement
Cr√©ation index, vues..
``` bash
node -e "steps=require('./src/steps'); steps.addEnrichment(require ('./src/config/extract-configuration-from-environment')())"
```


#### Ordonnanceur

Il est possible de faire tourner l'ordonnanceur en local.

Mettez la planification √† toutes les minutes dans le fichier `.env`

`SCHEDULE=* * * * *`

D√©marrez l'ordonnanceur

`node ./src/replication_job.js | ./node_modules/.bin/bunyan`

V√©rifiez que le traitement se lance
```shell
[2021-06-11T14:11:01.944Z]  INFO: pix-db-replication/83294 on OCTO-TOPI: Starting job in Learning Content replication queue: 10
```
V√©rifiez que bull a pu joindre redis
```shell
redis-cli
keys bull:*
```

Connectez-vous au CLI Bull pour suivre l'avancement.

Pour se connecter via Scalingo, utiliser le connect avec les 4 options ci-dessous.
connect [options] <queue>
    -h, --host <host>      Redis host for connection
    -p, --port <port>      Redis port for connection
    -d, --db <db>          Redis db for connection
    --password <password>  Redis password for connection
Puis saisir le nom de la queue.

Pour la r√©plication par dump
```shell
bull-repl
connect "Replication queue"
stats
```

Pour la r√©plication incr√©mentale
```shell
bull-repl
connect "Incremental replication queue"
stats
```

Pour l'import LCMS
```shell
bull-repl
connect "Learning Content replication queue"
stats
```

Vous obtenez, par exemple
- en cours d'ex√©cution d'un traitement
- apr√®s 14 ex√©cutions avec succ√®s

```shell
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  (index)  ‚îÇ Values ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  waiting  ‚îÇ   0    ‚îÇ
‚îÇ  active   ‚îÇ   1    ‚îÇ
‚îÇ completed ‚îÇ   14   ‚îÇ
‚îÇ  failed   ‚îÇ   0    ‚îÇ
‚îÇ  delayed  ‚îÇ   0    ‚îÇ
‚îÇ  paused   ‚îÇ   0    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```


## Tests
Une partie du code n'est pas testable de mani√®re automatis√©e.
Elle consiste en la r√©cup√©ration du backup.
Il est donc important d'effectuer un test manuel en RA avant de merger une PR, m√™me si la CI passe.

### Manuels

#### Local
R√©cup√©rer les donn√©es de LCMS :
``` bash
node -e "steps=require('./src/steps'); steps.importLearningContent();"
```

#### RA Scalingo
- Application Scalingo hors `osc-secnum-fr1` pour √©viter les consid√©rations de s√©curit√© des donn√©es

- V√©rifier les donn√©es pr√©sentes dans la BDD √† exporter

``` bash
$ scalingo -a pix-api-review-pr1973 pgsql-console
```

- Lancer un backup (ou ne rien faire, le dernier est utilis√© par d√©faut)

- D√©terminer le nom de l'application, par exemple : `pix-datawarehouse-pr47`
``` bash
NOM_APPLICATION=pix-datawarehouse-pr47
```

- Lancer le process de cr√©ation et d'import du backup
``` bash
scalingo run --region osc-fr1 --app pix-datawarehouse-pr<NUMERO-PR> --size S --detached node ./src/run.js
```

- V√©rifier le r√©sultat
``` bash
scalingo -a pix-datawarehouse-pr<NUMERO-PR> pgsql-console
```

```sql
SELECT id, email FROM "users" LIMIT 5;
```

### Automatis√©s

#### Local

##### Int√©gration
D√©roulement :
- une BDD est cr√©√©e en local sur l'URL `$TEST_POSTGRES_URL` (par d√©faut : `postgres://postgres@localhost`), instance `pix_replication_test`
- la table `test_table` est cr√©√©e et charg√©e avec 100 000 enregistrements (1 colonne, PK)
- un export est effectu√© par `pg_dump --c` dans un dossier temporaire
- la restauration √† tester est appel√©e depuis `steps.js/restoreBackup`
- les assertions SQL sont effectu√©es par un `runSql`, un wrapper autour de `psql`

_Note :_ le dump Scalingo est cr√©√© avec des options `pg_dump` [diff√©rentes](https://doc.scalingo.com/databases/postgresql/dump-restore)

- Se connecter √† la BDD de test :
``` bash
psql postgres://postgres@localhost/pix_replication_test
```

#### CI
La CI ex√©cute l'int√©gralit√© des tests (unitaire et int√©gration).

## Parser les logs
L'analyse de ce qui prend du temps est complexe sur les logs brutes s'il y a :
- plusieurs jobs de restauration (variable d'environnement`PG_RESTORE_JOBS`)
- beaucoup de tables.

Pour faciliter l'analyse, utilisez le script d'analyse de log.

√âtapes :
* r√©cup√©rer les logs
``` bash
scalingo --region osc-secnum-fr1 --app <NOM_APPLICATION> logs --lines 100000 > /tmp/logs.txt
```

* d√©terminer la date d'ex√©cution au format `YYYY-MM-DDDD`, par exemple : `2020-10-13`

* ex√©cuter
``` bash
node utils/parse-replication-logs.js ./logs.txt <DATE_EXECUTION>
```

Exemples de r√©sultat sur `pix-datawarehouse-production` le 22/10/2020
```  bash
node utils/parse-replication-logs.js ./logs.txt 2020-10-22
```

```                                                                                                                                                                                        1 ‚Üµ
Dur√©e de r√©cup√©ration du backup: 1h 27min 42s
Dur√©e de r√©plication: 8h 51min 17s
Dur√©e de l'enrichissement: 1h 39min 42s
Dur√©e totale: 11h 58min 41s
FK CONSTRAINT total duration : 7h 57min 25s
	FK CONSTRAINT schooling-registrations students_organizationid_foreign : 2h 11min 4s
	FK CONSTRAINT competence-evaluations competence_evaluations_assessmentid_foreign : 2h 10min 41s
	FK CONSTRAINT knowledge-elements knowledge_elements_answerid_foreign : 0h 58min 52s
CONSTRAINT total duration : 2h 49min 60s
	CONSTRAINT answers answers_pkey : 1h 26min 32s
	CONSTRAINT knowledge-elements knowledge-elements_pkey : 1h 13min 36s
	CONSTRAINT knowledge-element-snapshots knowledge-element-snapshots_pkey : 0h 2min 59s
INDEX total duration : 10h 21min 34s
	INDEX knowledge-elements_assessmentId_idx : 4h 16min 55s
	INDEX knowledge_elements_userid_index : 3h 49min 46s
	INDEX answers_assessmentid_index : 2h 7min 20s
SEQUENCE total duration : 0h 0min 28s
	SEQUENCE SET assessments_id_seq : 0h 0min 4s
	SEQUENCE SET user-orga-settings_id_seq : 0h 0min 3s
	SEQUENCE SET assessment-results_id_seq : 0h 0min 3s
TABLE DATA total duration : 4h 8min 7s
	TABLE DATA knowledge-element-snapshots : 1h 51min 60s
	TABLE DATA knowledge-elements : 1h 11min 25s
	TABLE DATA answers : 0h 46min 55s
```

S'il y a eu :
- plusieurs ex√©cutions le m√™me jour
- une ex√©cution incompl√®te (pas de message `Start restore` ou `Restore done`)

Alors vous obtiendrez le message suivant `TypeError: Cannot read property '0' of null`
