# R√©plication des donn√©es de production de Pix

Ce projet a pour but de r√©pliquer tout ou une partie des donn√©es d'une base de donn√©es postgreSQL:

- via une sauvegarde / restauration
- d'une mani√®re incr√©mentale

Des enrichissements peuvent √™tre fait √† la fin de l'import.

Les donn√©es de pix-editor/lcms sont √©galement r√©pliqu√©es.

A la fin du processus, nous notifions par webhooks des syst√®mes externes.

Ces √©tapes se font dans l'ordre et sont execut√©es sequentiellement dans des jobs [bull](https://github.com/OptimalBits/bull).

## Pr√©-requis

Ce projet est pr√©vu pour √™tre d√©ploy√© sur une application Scalingo associ√©e √† une base de donn√©e PostgreSQL.

Des variables d'environnement sont mises en place afin de garder un seul repository partag√© par les applications.

## Utilisation sur Scalingo

### Installation

Alimenter les variables d'environnement document√©es dans le fichier [sample.env](sample.env)

Pour satisfaire les contraintes de d√©ploiement Scalingo, le [Procfile](Procfile) d√©clare un conteneur de type `web` qui d√©marre un serveur Web "vide".

Une fois l'application cr√©√©e et d√©ploy√©e une premi√®re fois, il faut :
- mettre √† 0 le nombre de conteneurs de type `web`
- mettre √† 1 le nombre de conteneurs de type `background`
 
### R√©solution de probl√®mes

#### Analyse de la cause

Connectez-vous √† `bull`

```bash
scalingo --region osc-secnum-fr1 --app pix-datawarehouse-production run bull-repl
connect "Replication queue"
#connect "Incremental replication queue"
#connect "Learning Content replication queue"
failed
stats
```

Alternativement, se connecter √† `redis`

```bash
scalingo --region osc-secnum-fr1 --app pix-datawarehouse-production redis-console
KEYS *
GET <KEY>
```

#### Relance

Une fois que la cause du probl√®me a √©t√© corrig√©e:

- s'il est important que les donn√©es soient disponibles le jour m√™me, il est possible de lancer le traitement manuellement
- sinon ne rien faire, le traitement sera ex√©cut√© la nuit prochaine

> üß® Le traitement peut avoir des impacts sur les temps de r√©ponses des applications, car il utilise les ressources BDD.
> Monitorez le % CPU BDD et le temps de r√©ponse des requ√™tes HTTP pour arr√™ter le traitement si besoin. Pour cela, stopper le conteneur `background`.

Si la sauvegarde/restauration/enrichissement a √©chou√© :

``` bash
npm run restart:full-replication
```

Si la r√©plication incr√©mentale a √©chou√© :

``` bash
npm run restart:incremental-replication
```

Si la r√©plication de LCMS a √©chou√© :

``` bash
npm run restart:learning-content-replication
```

Si les notifications de fin ont √©chou√© :

``` bash
npm run restart:notification
```

## D√©veloppement et ex√©cution en local

### Installation

Installez le d√©p√¥t

``` bash
git clone git@github.com:1024pix/pix-db-replication.git && cd pix-db-replication
nvm use
npm run preinstall
```

D√©marrer le serveur de BDD

````bash
docker-compose up --detach
````

Cr√©er et charger les BDD

````bash
npm run local:setup-databases
````

V√©rifiez que la source et la cible sont accessibles et qu'elles contiennent des donn√©es

````bash
psql postgres://source_user@localhost/source_database
psql postgres://target_user@localhost/target_database
````

### Param√©trage

Cr√©er un fichier `.env` √† partir du fichier [sample.env](sample.env)

### Ex√©cution

#### R√©plication compl√®te

Modifier le .env

``` bash
DATABASE_URL=postgresql://target_user@localhost/target_database
BACKUP_MODE={}
RESTORE_FK_CONSTRAINTS=true
```

Lancer la r√©plication

``` bash
node -e "require('./src/steps/backup-restore').run(require ('./src/config/extract-configuration-from-environment')())"
```

Au bout de 5 minutes, vous devez obtenir le message

``` json
{"msg":"enrichment.add - Ended","time":"2021-01-08T08:26:13.000Z","v":0}
{"msg":"Import and enrichment done","time":"2021-01-08T08:26:13.000Z","v":0}
```

Pensez √† recr√©er le backup sur le filesystem local, supprim√© par la restauration

``` bash
git checkout data/source.pgsql
```

#### R√©plication incr√©mentale

##### Initialiser l'environnement

Supprimer les FK sortantes des tables √† copier

``` bash
psql postgresql://target_user@localhost/target_database
```

```sql
ALTER TABLE answers DROP CONSTRAINT "answers_assessmentid_foreign";
ALTER TABLE "knowledge-elements" DROP CONSTRAINT "knowledge_elements_answerid_foreign";
ALTER TABLE "knowledge-elements" DROP CONSTRAINT "knowledge_elements_assessmentid_foreign";
ALTER TABLE "knowledge-elements" DROP CONSTRAINT "knowledge_elements_userid_foreign";
```

##### Param√©trer

Modifier le .env

``` bash
SOURCE_DATABASE_URL=postgresql://source_user@localhost/source_database
TARGET_DATABASE_URL=postgresql://target_user@localhost/target_database
BACKUP_MODE='{"knowledge-elements":"incremental", "knowledge-element-snapshots":"incremental","answers":"incremental"}'
RESTORE_FK_CONSTRAINTS=false
```

#### Ordonnanceur

Il est possible de faire tourner l'ordonnanceur en local.

Mettez la planification √† toutes les minutes dans le fichier `.env`

`SCHEDULE=* * * * *`

D√©marrez l'ordonnanceur

`node ./src/main.js | ./node_modules/.bin/bunyan`

V√©rifiez que le traitement se lance

```bash
[2021-06-11T14:11:01.944Z]  INFO: pix-db-replication/83294 on OCTO-TOPI: Starting job in Learning Content replication queue: 10
```

V√©rifiez que bull a pu joindre redis

```bash
redis-cli
keys bull:*
```

Connectez-vous au CLI Bull pour suivre l'avancement.

Pour se connecter via Scalingo, utiliser le connect avec les 4 options ci-dessous.

``` bash
connect [options] <queue>
    -h, --host <host>      Redis host for connection
    -p, --port <port>      Redis port for connection
    -d, --db <db>          Redis db for connection
    --password <password>  Redis password for connection
```

Puis saisir le nom de la queue.

Pour la r√©plication par dump

```bash
bull-repl
connect "Replication queue"
stats
```

Pour la r√©plication incr√©mentale

```bash
bull-repl
connect "Incremental replication queue"
stats
```

Pour l'import LCMS

```bash
bull-repl
connect "Learning Content replication queue"
stats
```

Vous obtenez, par exemple
- en cours d'ex√©cution d'un traitement
- apr√®s 14 ex√©cutions avec succ√®s

```bash
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  (index)  ‚îÇ Values ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  waiting  ‚îÇ   0    ‚îÇ
‚îÇ  active   ‚îÇ   1    ‚îÇ
‚îÇ completed ‚îÇ   14   ‚îÇ
‚îÇ  failed   ‚îÇ   0    ‚îÇ
‚îÇ  delayed  ‚îÇ   0    ‚îÇ
‚îÇ  paused   ‚îÇ   0    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```


## Tests

Une partie du code n'est pas testable de mani√®re automatis√©e.

Il est donc important d'effectuer un test manuel en RA avant de merger une PR, m√™me si la CI passe.

### Manuels

#### Local

R√©cup√©rer les donn√©es de LCMS :

``` bash
node -e "require('./src/steps/learning-content').run(require ('./src/config/extract-configuration-from-environment')())"
```

#### RA Scalingo

- Faire un backup des donn√©es d'une application Scalingo hors `osc-secnum-fr1`
pour √©viter les consid√©rations de s√©curit√© des donn√©es

- V√©rifier les donn√©es pr√©sentes dans la BDD √† exporter (exemple pour les donn√©es d'une review app)

``` bash
scalingo -a pix-api-review-prxxx pgsql-console
```

- Lancer un backup (ou ne rien faire, le dernier est utilis√© par d√©faut)

- D√©terminer le nom de l'application de RA Scalingo de db-replication

``` bash
NOM_APPLICATION=pix-datawarehouse-pr<NUMERO-PR>
```

- Lancer le process de cr√©ation et d'import du backup sur cette RA

``` bash
scalingo run --region osc-fr1 --app $NOM_APPLICATION npm run restart:full-replication
```

- V√©rifier le r√©sultat dans la bdd r√©pliqu√©e

``` bash
scalingo -a $NOM_APPLICATION pgsql-console
```

```sql
SELECT id, email FROM "users" LIMIT 5;
```

### Automatis√©s

#### Local

##### Int√©gration

D√©roulement :

- une BDD est cr√©√©e en local sur l'URL `$TEST_POSTGRES_URL` (par d√©faut : `postgres://postgres@localhost`), instance `pix_replication_test`
- la table `test_table` est cr√©√©e et charg√©e avec 100 000 enregistrements (1 colonne, PK)
- un export est effectu√© par `pg_dump --c` dans un dossier temporaire
- la restauration √† tester est appel√©e depuis `steps.js/restoreBackup`
- les assertions SQL sont effectu√©es par un `runSql`, un wrapper autour de `psql`

> le dump Scalingo est cr√©√© avec des options `pg_dump` [diff√©rentes](https://doc.scalingo.com/databases/postgresql/dump-restore)

- Se connecter √† la BDD de test :

``` bash
psql postgres://postgres@localhost/pix_replication_test
```

#### CI

La CI ex√©cute l'int√©gralit√© des tests (unitaire et int√©gration).

## Parser les logs

### Datadog

Les logs en production sont pars√©s sur Datadog, et l'ensemble des √©l√©ments remontent dans des logs structur√©s.
Il est ainsi possible de filtrer sur les status des logs pour obtenir les informations d√©sir√©es.

### A la main

L'analyse de ce qui prend du temps est complexe sur les logs brutes s'il y a :

- plusieurs jobs de restauration (variable d'environnement`PG_RESTORE_JOBS`)
- beaucoup de tables.

Pour faciliter l'analyse, utilisez le script d'analyse de log.

√âtapes :

* r√©cup√©rer les logs

``` bash
scalingo --region osc-secnum-fr1 --app <NOM_APPLICATION> logs --lines 100000 > /tmp/logs.txt
```

* d√©terminer la date d'ex√©cution au format `YYYY-MM-DDDD`, par exemple : `2020-10-13`

* ex√©cuter
``` bash
node utils/parse-replication-logs.js ./logs.txt <DATE_EXECUTION>
```

Exemples de r√©sultat sur `pix-datawarehouse-production` le 22/10/2020
```  bash
node utils/parse-replication-logs.js ./logs.txt 2020-10-22
```

```

Dur√©e de r√©cup√©ration du backup: 1h 27min 42s
Dur√©e de r√©plication: 8h 51min 17s
Dur√©e de l'enrichissement: 1h 39min 42s
Dur√©e totale: 11h 58min 41s
FK CONSTRAINT total duration : 7h 57min 25s
	FK CONSTRAINT schooling-registrations students_organizationid_foreign : 2h 11min 4s
	FK CONSTRAINT competence-evaluations competence_evaluations_assessmentid_foreign : 2h 10min 41s
	FK CONSTRAINT knowledge-elements knowledge_elements_answerid_foreign : 0h 58min 52s
CONSTRAINT total duration : 2h 49min 60s
	CONSTRAINT answers answers_pkey : 1h 26min 32s
	CONSTRAINT knowledge-elements knowledge-elements_pkey : 1h 13min 36s
	CONSTRAINT knowledge-element-snapshots knowledge-element-snapshots_pkey : 0h 2min 59s
INDEX total duration : 10h 21min 34s
	INDEX knowledge-elements_assessmentId_idx : 4h 16min 55s
	INDEX knowledge_elements_userid_index : 3h 49min 46s
	INDEX answers_assessmentid_index : 2h 7min 20s
SEQUENCE total duration : 0h 0min 28s
	SEQUENCE SET assessments_id_seq : 0h 0min 4s
	SEQUENCE SET user-orga-settings_id_seq : 0h 0min 3s
	SEQUENCE SET assessment-results_id_seq : 0h 0min 3s
TABLE DATA total duration : 4h 8min 7s
	TABLE DATA knowledge-element-snapshots : 1h 51min 60s
	TABLE DATA knowledge-elements : 1h 11min 25s
	TABLE DATA answers : 0h 46min 55s
```

S'il y a eu :
- plusieurs ex√©cutions le m√™me jour
- une ex√©cution incompl√®te (pas de message `Start restore` ou `Restore done`)

Alors vous obtiendrez le message suivant `TypeError: Cannot read property '0' of null`

## Duplication des sch√©mas uniquement

Afin de pouvoir alimenter une base de donn√©es contenant uniquement le sch√©ma de BDD, notamment pour des besoins de Data Catalog,
le script `db-schema-exporter.sh` peut √™tre utilis√©.

En d√©finissant les variables suivantes :

```bash
DB_SCHEMA_EXPORTER_ENABLED=true
DB_SCHEMA_EXPORTER_DATABASE_TARGET=postgres://user:password@database:port/db
```

Tous les jours √† midi, le sch√©ma de la base actuelle sera dupliqu√© sur la BDD distante.

# Lancer la sauvegarde de la base √† la main

``` bash
node -e "require('./src/steps/dump-and-push-on-S3').run(require ('./src/config/extract-configuration-from-environment')())"
```
